{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":102672,"databundleVersionId":12375409,"sourceType":"competition"},{"sourceId":11929710,"sourceType":"datasetVersion","datasetId":7500081}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================ Imports ============================\nimport os\nimport pandas as pandas_lib\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torch.nn as neural_network\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\n\n# ============================ Data Preprocessing ============================\n\n# Load CSV files containing training labels and test image IDs\ntraining_dataframe = pandas_lib.read_csv('/kaggle/input/soil-classification/soil_classification-2025/train_labels.csv')\ntesting_dataframe = pandas_lib.read_csv('/kaggle/input/soil-classification/soil_classification-2025/test_ids.csv')\n\n# Add full image paths to the dataframes\ntraining_dataframe['image_path'] = '/kaggle/input/soil-classification/soil_classification-2025/train/' + training_dataframe['image_id']\ntesting_dataframe['image_path'] = '/kaggle/input/soil-classification/soil_classification-2025/test/' + testing_dataframe['image_id']\n\n# Map each unique soil type to an integer label\nlabel_to_index_mapping = {label: index for index, label in enumerate(training_dataframe['soil_type'].unique())}\nindex_to_label_mapping = {index: label for label, index in label_to_index_mapping.items()}\ntraining_dataframe['label_index'] = training_dataframe['soil_type'].map(label_to_index_mapping)\n\n# Split training data into training and validation sets using stratified sampling\ntraining_subset, validation_subset = train_test_split(\n    training_dataframe,\n    test_size=0.1,\n    stratify=training_dataframe['label_index'],\n    random_state=42\n)\n\n# ============================ Image Transformations ============================\n\nimage_transformation = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor()\n])\n\n# ============================ Dataset Definition ============================\n\nclass SoilImageDataset(Dataset):\n    def __init__(self, dataframe, transform=None, is_testing=False):\n        self.dataframe = dataframe\n        self.transform = transform\n        self.is_testing = is_testing\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, index):\n        image_path = self.dataframe.iloc[index]['image_path']\n        image = Image.open(image_path).convert('RGB')\n\n        if self.transform:\n            image = self.transform(image)\n\n        if self.is_testing:\n            return image\n        else:\n            label = self.dataframe.iloc[index]['label_index']\n            return image, label\n\n# ============================ Data Loaders ============================\n\ntraining_loader = DataLoader(SoilImageDataset(training_subset, image_transformation), batch_size=32, shuffle=True)\nvalidation_loader = DataLoader(SoilImageDataset(validation_subset, image_transformation), batch_size=32)\ntesting_loader = DataLoader(SoilImageDataset(testing_dataframe, image_transformation, is_testing=True), batch_size=32)\n\n# ============================ Model Setup ============================\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = models.resnet18()  \nstate_dict = torch.load(\"/kaggle/input/resnet18/resnet18-f37072fd.pth\", map_location=device)\nmodel.load_state_dict(state_dict)\n\nmodel.fc = neural_network.Linear(model.fc.in_features, len(label_to_index_mapping))  # Output layer for 4 classes\nmodel = model.to(device)\n\nloss_function = neural_network.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n\n# ============================ Optional Training Augmentations ============================\n\ntraining_augmentation = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    transforms.ToTensor()\n])\n\n# ============================ Model Training Function ============================\n\ndef train_model(number_of_epochs=5):\n    best_validation_accuracy = 0.0\n\n    for epoch_number in range(number_of_epochs):\n        model.train()\n        total_training_loss = 0.0\n        correct_training_predictions = 0\n        total_training_samples = 0\n\n        for images, labels in training_loader:\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n\n            loss = loss_function(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            total_training_loss += loss.item() * images.size(0)\n            _, predicted_classes = torch.max(outputs, 1)\n            correct_training_predictions += (predicted_classes == labels).sum().item()\n            total_training_samples += labels.size(0)\n\n        training_accuracy = correct_training_predictions / total_training_samples\n        print(f\"Epoch {epoch_number+1}, Loss: {total_training_loss/total_training_samples:.4f}, Accuracy: {training_accuracy:.4f}\")\n\n        # ============================ Model Validation ============================\n        model.eval()\n        correct_validation_predictions = 0\n        total_validation_samples = 0\n\n        with torch.no_grad():\n            for images, labels in validation_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted_classes = torch.max(outputs, 1)\n                correct_validation_predictions += (predicted_classes == labels).sum().item()\n                total_validation_samples += labels.size(0)\n\n        validation_accuracy = correct_validation_predictions / total_validation_samples\n        print(f\"Validation Accuracy: {validation_accuracy:.4f}\")\n\n        # Save the best model\n        if validation_accuracy > best_validation_accuracy:\n            best_validation_accuracy = validation_accuracy\n            torch.save(model.state_dict(), \"best_soil_model.pth\")\n            print(\"✅ Saved new best model\")\n\n# Train the model\ntrain_model(number_of_epochs=5)\n\n# ============================ Inference on Test Set ============================\n\n# Load the best model and switch to evaluation mode\nmodel.load_state_dict(torch.load(\"best_soil_model.pth\"))\nmodel.eval()\n\npredicted_indices = []\nwith torch.no_grad():\n    for images in testing_loader:\n        images = images.to(device)\n        outputs = model(images)\n        _, predicted_classes = torch.max(outputs, 1)\n        predicted_indices.extend(predicted_classes.cpu().numpy())\n\n# ============================ Submission File Generation ============================\n\n# Map predicted indices to original soil type labels\ntesting_dataframe['predicted_label'] = [index_to_label_mapping[predicted_index] for predicted_index in predicted_indices]\n\n# Format the submission DataFrame\nsubmission_dataframe = testing_dataframe[['image_id', 'predicted_label']].rename(columns={'predicted_label': 'soil_type'})\nsubmission_dataframe.to_csv(\"submission.csv\", index=False)\n\nprint(\"✅ Submission file has been saved as 'submission.csv'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:52:26.388570Z","iopub.execute_input":"2025-05-24T10:52:26.389463Z","iopub.status.idle":"2025-05-24T11:06:38.678525Z","shell.execute_reply.started":"2025-05-24T10:52:26.389431Z","shell.execute_reply":"2025-05-24T11:06:38.677687Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 0.4140, Accuracy: 0.8517\nValidation Accuracy: 0.9919\n✅ Saved new best model\nEpoch 2, Loss: 0.0804, Accuracy: 0.9763\nValidation Accuracy: 0.9919\nEpoch 3, Loss: 0.0401, Accuracy: 0.9909\nValidation Accuracy: 1.0000\n✅ Saved new best model\nEpoch 4, Loss: 0.0174, Accuracy: 0.9973\nValidation Accuracy: 1.0000\nEpoch 5, Loss: 0.0222, Accuracy: 0.9945\nValidation Accuracy: 1.0000\n✅ Submission file has been saved as 'submission.csv'\n","output_type":"stream"}],"execution_count":12}]}